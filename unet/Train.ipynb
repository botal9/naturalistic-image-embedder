{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from options.train_options import TrainOptions\n",
    "from data import create_dataset\n",
    "from models import create_model\n",
    "from util.visualizer import Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'gen24'\n",
    "\n",
    "# defaults = {\n",
    "#     'dataroot': '../../hdr_out/06_Apr_14_16_50',\n",
    "#     'model': 'hdr',\n",
    "#     'dataset_mode': 'hdr',\n",
    "#     'dataset_root': '../../hdr_out/06_Apr_14_16_50',\n",
    "#     'embedding_save_dir': '',\n",
    "#     'name': NAME\n",
    "# }\n",
    "\n",
    "defaults = {\n",
    "    'dataroot': '../../generator_data/HFlickr/',\n",
    "    'model': 'my',\n",
    "    'dataset_mode': 'my',\n",
    "    'dataset_root': '../../generator_data/HFlickr/',\n",
    "    'embedding_save_dir': './checkpoints/emb2',\n",
    "    'name': NAME\n",
    "}\n",
    "\n",
    "# defaults = {\n",
    "#     'dataroot': '../../embedding_data/vidit/',\n",
    "#     'model': 'emb',\n",
    "#     'dataset_mode': 'emb',\n",
    "#     'dataset_root': '../../embedding_data/vidit/',\n",
    "# #     'embedding_save_dir': './checkpoints/hdr1/',\n",
    "#     'name': NAME\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "opt = TrainOptions(defaults=defaults).parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert opt.isTrain == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(opt)  # create a dataset given opt.dataset_mode and other options\n",
    "dataset_size = len(dataset)    # get the number of images in the dataset.\n",
    "print('The number of training images = %d' % dataset_size)\n",
    "\n",
    "model = create_model(opt)      # create a model given opt.model and other options\n",
    "model.setup(opt)               # regular setup: load and print networks; create schedulers\n",
    "visualizer = Visualizer(opt)   # create a visualizer that display/save images and plots\n",
    "total_iters = 0                # the total number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(tensor):\n",
    "    np_img = np.squeeze(tensor.detach().to('cpu').numpy())\n",
    "    np_img = np_img.transpose((1, 2, 0))\n",
    "    np_img = cv2.cvtColor(np_img, cv2.COLOR_RGBA2RGB)\n",
    "    return np_img\n",
    "    \n",
    "\n",
    "def display(visuals, epoch):\n",
    "    real = to_img(visuals['real'])\n",
    "    comp = to_img(visuals['comp'])\n",
    "    harmonized = to_img(visuals['harmonized'])\n",
    "    \n",
    "    print(f'Epoch {epoch} composition/real/harmonized')\n",
    "    display = np.concatenate([comp, real, harmonized], axis=1)\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(display)\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss_dynamics(X, Y):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.plot(X, Y, label='L1 norm')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_losses = []\n",
    "epochs = []\n",
    "\n",
    "for epoch in range(opt.epoch_count, opt.niter + opt.niter_decay + 1):\n",
    "    epoch_start_time = time.time()  # timer for entire epoch\n",
    "    iter_data_time = time.time()    # timer for data loading per iteration\n",
    "    epoch_iter = 0                  # the number of training iterations in current epoch, reset to 0 every epoch\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    for i, data in enumerate(dataset):  # inner loop within one epoch\n",
    "        iter_start_time = time.time()  # timer for computation per iteration\n",
    "        if total_iters % opt.print_freq == 0:\n",
    "            t_data = iter_start_time - iter_data_time\n",
    "        visualizer.reset()\n",
    "        total_iters += opt.batch_size\n",
    "        epoch_iter += opt.batch_size\n",
    "        model.set_input(data)         # unpack data from dataset and apply preprocessing\n",
    "        model.optimize_parameters()   # calculate loss functions, get gradients, update network weights\n",
    "\n",
    "        if total_iters % opt.display_freq == 0:   # display images on visdom and save images to a HTML file\n",
    "            save_result = total_iters % opt.update_html_freq == 0\n",
    "            model.compute_visuals()\n",
    "            display(model.get_current_visuals(), epoch)\n",
    "\n",
    "        if total_iters % opt.print_freq == 0:    \n",
    "            losses = model.get_current_losses()\n",
    "            t_comp = (time.time() - iter_start_time) / opt.batch_size\n",
    "            visualizer.print_current_losses(epoch, epoch_iter, losses, t_comp, t_data)\n",
    "            epoch_loss += losses['G_L1']\n",
    "\n",
    "        if total_iters % opt.save_latest_freq == 0:   \n",
    "            print('saving the latest model (epoch %d, total_iters %d)' % (epoch, total_iters))\n",
    "            save_suffix = 'iter_%d' % total_iters if opt.save_by_iter else 'latest'\n",
    "            model.save_networks(save_suffix)\n",
    "\n",
    "        iter_data_time = time.time()\n",
    "    if epoch % opt.save_epoch_freq == 0:              # cache our model every <save_epoch_freq> epochs\n",
    "        print('saving the model at the end of epoch %d, iters %d' % (epoch, total_iters))\n",
    "        model.save_networks('latest')\n",
    "        model.save_networks(epoch)\n",
    "\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' % \n",
    "              (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    epochs.append(epoch)\n",
    "    plot_loss_dynamics(epochs, epoch_losses)\n",
    "    \n",
    "    model.update_learning_rate()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-determination",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
