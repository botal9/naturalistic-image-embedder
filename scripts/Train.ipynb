{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dangerous-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from options.train_options import TrainOptions\n",
    "from data import create_dataset\n",
    "from models import create_model\n",
    "from util.local_visualizer import LocalVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "south-instruction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "               d_lr_ratio: 1.0                           \n",
      "                 dataroot: ../../generator_data/         \n",
      "             dataset_mode: my                            \n",
      "             dataset_root: ../../generator_data/         \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 9333                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "       embedding_save_dir: ./checkpoints/emb_vidit4      \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "               g_lr_ratio: 1.0                           \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 5                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: my                            \n",
      "               n_layers_D: 3                             \n",
      "                     name: gen_new5                      \n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "       new_dataset_option: 2.0                           \n",
      "                      ngf: 64                            \n",
      "                    niter: 80                            \n",
      "              niter_decay: 80                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: True                          \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: none                          \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n"
     ]
    }
   ],
   "source": [
    "NAME = 'gen_new5'\n",
    "DS_NAME = ''\n",
    "\n",
    "defaults = {\n",
    "    'dataroot': f'../../generator_data/{DS_NAME}',\n",
    "    'model': 'my',\n",
    "    'dataset_mode': 'my',\n",
    "    'dataset_root': f'../../generator_data/{DS_NAME}',\n",
    "    'embedding_save_dir': './checkpoints/emb_vidit4',\n",
    "    'name': NAME\n",
    "}\n",
    "\n",
    "# defaults = {\n",
    "#     'dataroot': '../../embedding_data/vidit/',\n",
    "#     'model': 'emb',\n",
    "#     'dataset_mode': 'emb',\n",
    "#     'dataset_root': '../../embedding_data/vidit/',\n",
    "#     'name': NAME\n",
    "# }\n",
    "\n",
    "\n",
    "opt = TrainOptions(defaults=defaults).parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intimate-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt.save_epoch_freq = 10\n",
    "# opt.display_freq = 1000\n",
    "# opt.print_freq = 200\n",
    "# opt.save_latest_freq = 10000\n",
    "# opt.batch_size = 8\n",
    "\n",
    "opt.beta1 = 0.9\n",
    "\n",
    "opt.save_epoch_freq = 10\n",
    "opt.display_freq = 40000\n",
    "opt.print_freq = 8000\n",
    "opt.save_latest_freq = 60000\n",
    "opt.batch_size = 32\n",
    "\n",
    "assert opt.isTrain == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "animated-contemporary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train file\n",
      "dataset [MyDataset] was created\n",
      "The number of training images = 65699\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "loading the model from ./checkpoints/emb_vidit4/150_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.415 M\n",
      "-----------------------------------------------\n",
      "model [MyModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 73.946 M\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "datasets = {}\n",
    "dataset_sizes = {}\n",
    "\n",
    "datasets['train'] = create_dataset(opt)  # create a dataset given opt.dataset_mode and other options\n",
    "dataset_sizes['train'] = len(datasets['train'])    # get the number of images in the dataset.\n",
    "print('The number of training images = %d' % dataset_sizes['train'])\n",
    "\n",
    "model = create_model(opt)      # create a model given opt.model and other options\n",
    "model.setup(opt)               # regular setup: load and print networks; create schedulers\n",
    "visualizer = LocalVisualizer(opt)   # create a visualizer that display/save images and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "perceived-reynolds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test file\n",
      "dataset [MyDataset] was created\n",
      "The number of test images = 7393\n"
     ]
    }
   ],
   "source": [
    "opt.isTrain = False\n",
    "\n",
    "train_batch_size = opt.batch_size\n",
    "test_batch_size = 1\n",
    "\n",
    "opt.num_threads = 0   # test code only supports num_threads = 0\n",
    "opt.batch_size = test_batch_size    # test code only supports batch_size = 1\n",
    "opt.serial_batches = True  # disable data shuffling;\n",
    "\n",
    "datasets['test'] = create_dataset(opt)  # create a dataset given opt.dataset_mode and other options\n",
    "dataset_sizes['test'] = len(datasets['test'])    # get the number of images in the dataset.\n",
    "print('The number of test images = %d' % dataset_sizes['test'])\n",
    "ds_ratio = dataset_sizes['train'] / dataset_sizes['test']\n",
    "\n",
    "opt.batch_size = train_batch_size\n",
    "opt.isTrain = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "partial-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import mean_squared_error as mse\n",
    "import torchvision.transforms as tf\n",
    "\n",
    "\n",
    "class NormalizeInverse(tf.Normalize):\n",
    "    \"\"\"\n",
    "    Undoes the normalization and returns the reconstructed images in the input domain.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        mean = torch.as_tensor(mean)\n",
    "        std = torch.as_tensor(std)\n",
    "        std_inv = 1 / (std + 1e-7)\n",
    "        mean_inv = -mean * std_inv\n",
    "        super().__init__(mean=mean_inv, std=std_inv)\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return super().__call__(tensor)\n",
    "    \n",
    "unnorm = NormalizeInverse((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "    \n",
    "def to_img(tensor):\n",
    "    tensor = torch.squeeze(tensor.detach().to('cpu'))\n",
    "    if unnorm is not None:\n",
    "        tensor = unnorm(tensor)\n",
    "    np_img = tensor.numpy()\n",
    "    np_img = np_img.transpose((1, 2, 0))\n",
    "    return (np_img.clip(0, 1) * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "explicit-windsor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Train epoch 1 / 160 \t Time Taken: 632.500 sec\n",
      "End of Train epoch 2 / 160 \t Time Taken: 640.488 sec\n",
      "End of Train epoch 3 / 160 \t Time Taken: 596.464 sec\n",
      "End of Train epoch 4 / 160 \t Time Taken: 596.667 sec\n",
      "End of Train epoch 6 / 160 \t Time Taken: 596.773 sec\n",
      "End of Train epoch 7 / 160 \t Time Taken: 596.393 sec\n",
      "End of Train epoch 8 / 160 \t Time Taken: 610.868 sec\n",
      "End of Train epoch 9 / 160 \t Time Taken: 659.157 sec\n",
      "saving the model at the end of epoch 10, iters 0\n",
      "End of Train epoch 10 / 160 \t Time Taken: 764.822 sec\n",
      "End of Train epoch 11 / 160 \t Time Taken: 596.125 sec\n",
      "End of Train epoch 12 / 160 \t Time Taken: 596.696 sec\n",
      "End of Train epoch 13 / 160 \t Time Taken: 596.125 sec\n",
      "End of Train epoch 14 / 160 \t Time Taken: 596.490 sec\n",
      "End of Train epoch 15 / 160 \t Time Taken: 596.669 sec\n",
      "End of Train epoch 16 / 160 \t Time Taken: 671.992 sec\n",
      "End of Train epoch 17 / 160 \t Time Taken: 595.984 sec\n",
      "End of Train epoch 18 / 160 \t Time Taken: 595.905 sec\n",
      "End of Train epoch 19 / 160 \t Time Taken: 596.170 sec\n",
      "saving the model at the end of epoch 20, iters 0\n",
      "End of Train epoch 20 / 160 \t Time Taken: 597.966 sec\n",
      "End of Train epoch 21 / 160 \t Time Taken: 595.931 sec\n",
      "End of Train epoch 22 / 160 \t Time Taken: 596.262 sec\n",
      "End of Train epoch 23 / 160 \t Time Taken: 672.046 sec\n",
      "End of Train epoch 24 / 160 \t Time Taken: 596.359 sec\n",
      "End of Train epoch 25 / 160 \t Time Taken: 595.804 sec\n",
      "End of Train epoch 26 / 160 \t Time Taken: 596.038 sec\n",
      "End of Train epoch 27 / 160 \t Time Taken: 595.895 sec\n",
      "End of Train epoch 28 / 160 \t Time Taken: 596.009 sec\n",
      "End of Train epoch 29 / 160 \t Time Taken: 596.184 sec\n",
      "saving the model at the end of epoch 30, iters 0\n",
      "End of Train epoch 30 / 160 \t Time Taken: 675.546 sec\n",
      "End of Train epoch 31 / 160 \t Time Taken: 596.365 sec\n",
      "End of Train epoch 32 / 160 \t Time Taken: 596.553 sec\n",
      "End of Train epoch 33 / 160 \t Time Taken: 596.079 sec\n",
      "End of Train epoch 34 / 160 \t Time Taken: 596.075 sec\n",
      "End of Train epoch 35 / 160 \t Time Taken: 596.726 sec\n",
      "End of Train epoch 36 / 160 \t Time Taken: 596.851 sec\n",
      "End of Train epoch 37 / 160 \t Time Taken: 673.772 sec\n",
      "End of Train epoch 38 / 160 \t Time Taken: 595.978 sec\n",
      "End of Train epoch 39 / 160 \t Time Taken: 596.294 sec\n",
      "saving the model at the end of epoch 40, iters 0\n",
      "End of Train epoch 40 / 160 \t Time Taken: 598.151 sec\n",
      "saving the model at the end of epoch 40, iters 0\n",
      "End of Test epoch 40 / 160 \t Time Taken: 312.181 sec\n",
      "Updating best model at epoch 40, average test loss: 73.2296\n",
      "End of Train epoch 41 / 160 \t Time Taken: 592.497 sec\n",
      "End of Test epoch 41 / 160 \t Time Taken: 309.784 sec\n",
      "End of Train epoch 42 / 160 \t Time Taken: 661.493 sec\n",
      "End of Test epoch 42 / 160 \t Time Taken: 309.396 sec\n",
      "Updating best model at epoch 42, average test loss: 69.5635\n",
      "End of Train epoch 43 / 160 \t Time Taken: 592.699 sec\n",
      "End of Test epoch 43 / 160 \t Time Taken: 309.521 sec\n",
      "End of Train epoch 44 / 160 \t Time Taken: 593.321 sec\n",
      "End of Test epoch 44 / 160 \t Time Taken: 309.261 sec\n",
      "End of Train epoch 45 / 160 \t Time Taken: 597.092 sec\n",
      "End of Test epoch 45 / 160 \t Time Taken: 337.898 sec\n",
      "End of Train epoch 46 / 160 \t Time Taken: 593.295 sec\n",
      "End of Test epoch 46 / 160 \t Time Taken: 309.429 sec\n",
      "End of Train epoch 47 / 160 \t Time Taken: 592.847 sec\n",
      "End of Test epoch 47 / 160 \t Time Taken: 309.564 sec\n",
      "End of Train epoch 48 / 160 \t Time Taken: 592.689 sec\n",
      "End of Test epoch 48 / 160 \t Time Taken: 312.539 sec\n",
      "End of Train epoch 49 / 160 \t Time Taken: 642.500 sec\n",
      "End of Test epoch 49 / 160 \t Time Taken: 310.435 sec\n",
      "saving the model at the end of epoch 50, iters 0\n",
      "End of Train epoch 50 / 160 \t Time Taken: 595.219 sec\n",
      "saving the model at the end of epoch 50, iters 0\n",
      "End of Test epoch 50 / 160 \t Time Taken: 315.942 sec\n",
      "End of Train epoch 51 / 160 \t Time Taken: 592.247 sec\n",
      "End of Test epoch 51 / 160 \t Time Taken: 310.441 sec\n",
      "End of Train epoch 52 / 160 \t Time Taken: 661.335 sec\n",
      "End of Test epoch 52 / 160 \t Time Taken: 325.116 sec\n",
      "Updating best model at epoch 52, average test loss: 69.4019\n",
      "End of Train epoch 53 / 160 \t Time Taken: 593.387 sec\n",
      "End of Test epoch 53 / 160 \t Time Taken: 310.195 sec\n",
      "End of Train epoch 54 / 160 \t Time Taken: 593.376 sec\n",
      "End of Test epoch 54 / 160 \t Time Taken: 309.910 sec\n",
      "End of Train epoch 55 / 160 \t Time Taken: 592.816 sec\n",
      "End of Test epoch 55 / 160 \t Time Taken: 338.543 sec\n",
      "End of Train epoch 56 / 160 \t Time Taken: 592.875 sec\n",
      "End of Test epoch 56 / 160 \t Time Taken: 310.404 sec\n",
      "End of Train epoch 57 / 160 \t Time Taken: 592.592 sec\n",
      "End of Test epoch 57 / 160 \t Time Taken: 309.541 sec\n",
      "End of Train epoch 58 / 160 \t Time Taken: 592.814 sec\n",
      "End of Test epoch 58 / 160 \t Time Taken: 310.117 sec\n",
      "End of Train epoch 59 / 160 \t Time Taken: 662.690 sec\n",
      "End of Test epoch 59 / 160 \t Time Taken: 309.715 sec\n",
      "saving the model at the end of epoch 60, iters 0\n",
      "End of Train epoch 60 / 160 \t Time Taken: 595.379 sec\n",
      "saving the model at the end of epoch 60, iters 0\n",
      "End of Test epoch 60 / 160 \t Time Taken: 313.502 sec\n",
      "End of Train epoch 61 / 160 \t Time Taken: 593.513 sec\n",
      "End of Test epoch 61 / 160 \t Time Taken: 310.585 sec\n",
      "End of Train epoch 62 / 160 \t Time Taken: 618.403 sec\n",
      "End of Test epoch 62 / 160 \t Time Taken: 329.133 sec\n",
      "End of Train epoch 63 / 160 \t Time Taken: 593.009 sec\n",
      "End of Test epoch 63 / 160 \t Time Taken: 310.456 sec\n",
      "End of Train epoch 64 / 160 \t Time Taken: 592.496 sec\n",
      "End of Test epoch 64 / 160 \t Time Taken: 310.226 sec\n",
      "End of Train epoch 65 / 160 \t Time Taken: 592.705 sec\n",
      "End of Test epoch 65 / 160 \t Time Taken: 317.630 sec\n",
      "Updating best model at epoch 65, average test loss: 69.1895\n",
      "End of Train epoch 66 / 160 \t Time Taken: 621.541 sec\n",
      "End of Test epoch 66 / 160 \t Time Taken: 309.610 sec\n",
      "End of Train epoch 67 / 160 \t Time Taken: 592.912 sec\n",
      "End of Test epoch 67 / 160 \t Time Taken: 309.795 sec\n",
      "End of Train epoch 68 / 160 \t Time Taken: 593.927 sec\n",
      "End of Train epoch 69 / 160 \t Time Taken: 662.780 sec\n",
      "End of Test epoch 69 / 160 \t Time Taken: 310.054 sec\n",
      "saving the model at the end of epoch 70, iters 0\n",
      "End of Train epoch 70 / 160 \t Time Taken: 596.625 sec\n",
      "saving the model at the end of epoch 70, iters 0\n",
      "End of Test epoch 70 / 160 \t Time Taken: 312.994 sec\n",
      "End of Train epoch 71 / 160 \t Time Taken: 594.695 sec\n",
      "End of Test epoch 71 / 160 \t Time Taken: 310.933 sec\n",
      "End of Train epoch 72 / 160 \t Time Taken: 594.639 sec\n",
      "End of Test epoch 72 / 160 \t Time Taken: 339.847 sec\n",
      "End of Train epoch 73 / 160 \t Time Taken: 594.717 sec\n",
      "End of Test epoch 73 / 160 \t Time Taken: 311.029 sec\n",
      "End of Train epoch 74 / 160 \t Time Taken: 594.360 sec\n",
      "End of Test epoch 74 / 160 \t Time Taken: 310.907 sec\n",
      "End of Train epoch 75 / 160 \t Time Taken: 594.911 sec\n",
      "End of Test epoch 75 / 160 \t Time Taken: 311.224 sec\n",
      "End of Train epoch 76 / 160 \t Time Taken: 663.409 sec\n",
      "End of Test epoch 76 / 160 \t Time Taken: 310.566 sec\n",
      "End of Train epoch 77 / 160 \t Time Taken: 594.528 sec\n",
      "End of Test epoch 77 / 160 \t Time Taken: 310.955 sec\n",
      "End of Train epoch 78 / 160 \t Time Taken: 594.493 sec\n",
      "End of Test epoch 78 / 160 \t Time Taken: 311.190 sec\n",
      "End of Train epoch 79 / 160 \t Time Taken: 629.636 sec\n",
      "End of Test epoch 79 / 160 \t Time Taken: 331.306 sec\n",
      "saving the model at the end of epoch 80, iters 0\n",
      "End of Train epoch 80 / 160 \t Time Taken: 596.069 sec\n",
      "saving the model at the end of epoch 80, iters 0\n",
      "End of Test epoch 80 / 160 \t Time Taken: 311.825 sec\n",
      "End of Train epoch 81 / 160 \t Time Taken: 594.601 sec\n",
      "End of Test epoch 81 / 160 \t Time Taken: 311.599 sec\n",
      "End of Train epoch 82 / 160 \t Time Taken: 594.504 sec\n",
      "End of Test epoch 82 / 160 \t Time Taken: 320.898 sec\n",
      "End of Train epoch 83 / 160 \t Time Taken: 611.425 sec\n",
      "End of Test epoch 83 / 160 \t Time Taken: 311.157 sec\n",
      "Updating best model at epoch 83, average test loss: 68.6530\n",
      "End of Train epoch 84 / 160 \t Time Taken: 594.968 sec\n",
      "End of Test epoch 84 / 160 \t Time Taken: 310.685 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-41458d2ba3a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#             epoch_iter += batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# unpack data from dataset and apply preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Image_Harmonization_Datasets/U-Net+attention/models/my_model.py\u001b[0m in \u001b[0;36mset_input\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;31m#         white_mask = torch.ones_like(mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_iters = 0\n",
    "train_iters = 0\n",
    "min_test_loss = math.inf\n",
    "\n",
    "phases = ['train']\n",
    "# model.train()\n",
    "# phases.append('test')\n",
    "\n",
    "for epoch in range(opt.epoch_count, opt.niter + opt.niter_decay + 1):\n",
    "    visualizer.set_epoch(epoch)\n",
    "\n",
    "    if epoch == 40:\n",
    "        phases.append('test')\n",
    "    \n",
    "    for phase in phases:\n",
    "        epoch_start_time = time.time()  # timer for entire epoch\n",
    "#         iter_data_time = time.time()    # timer for data loading per iteration\n",
    "        epoch_iter = 0                  # the number of training iterations in current epoch\n",
    "        epoch_loss = 0.0\n",
    "        dataset = datasets[phase]\n",
    "        visualizer.set_phase(phase)\n",
    "        \n",
    "        if phase == 'train':\n",
    "            isTrain = True\n",
    "            batch_size = train_batch_size\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            isTrain = False\n",
    "            batch_size = test_batch_size\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "        \n",
    "        for data in dataset:  # inner loop within one epoch\n",
    "#             iter_start_time = time.time()  # timer for computation per iteration\n",
    "#             if total_iters % opt.print_freq == 0:\n",
    "#                 t_data = iter_start_time - iter_data_time\n",
    "            \n",
    "#             if isTrain:\n",
    "#                 train_iters += batch_size\n",
    "#             total_iters += batch_size\n",
    "#             epoch_iter += batch_size\n",
    "            \n",
    "            model.set_input(data)         # unpack data from dataset and apply preprocessing\n",
    "\n",
    "            if phase == 'train':\n",
    "                model.optimize_parameters()   # calculate loss functions, get gradients, update network weights\n",
    "            else:\n",
    "                model.test()\n",
    "                \n",
    "                real = to_img(model.real)\n",
    "                harmonized = to_img(model.harmonized)\n",
    "                epoch_loss += mse(harmonized, real)\n",
    "\n",
    "#             losses = model.get_current_losses()\n",
    "#             epoch_loss += losses['G_L1']\n",
    "                \n",
    "#             if total_iters % opt.display_freq == 0:   # display images \n",
    "#                 model.compute_visuals()\n",
    "#                 visualizer.display_visuals(model.get_current_visuals())\n",
    "\n",
    "#             if total_iters % opt.print_freq == 0:    \n",
    "#                 losses = model.get_current_losses()\n",
    "#                 t_comp = (time.time() - iter_start_time) / opt.batch_size\n",
    "#                 visualizer.print_current_losses(epoch_iter, losses, t_comp, t_data)\n",
    "\n",
    "#             if isTrain and train_iters % opt.save_latest_freq == 0:   \n",
    "#                 print('saving the latest model (epoch %d, train_iters %d)' % (epoch, train_iters))\n",
    "#                 save_suffix = 'iter_%d' % train_iters if opt.save_by_iter else 'latest'\n",
    "#                 model.save_networks(save_suffix)\n",
    "\n",
    "#             iter_data_time = time.time()\n",
    "\n",
    "        if phase == 'train' epoch % opt.save_epoch_freq == 0:              # cache our model every <save_epoch_freq> epochs\n",
    "            print('saving the model at the end of epoch %d, iters %d' % (epoch, total_iters))\n",
    "            model.save_networks('latest')\n",
    "            model.save_networks(epoch)\n",
    "\n",
    "        print(f'End of {phase.capitalize()} epoch {epoch} / {opt.niter+opt.niter_decay} \\t ',\n",
    "              f'Time Taken: {time.time() - epoch_start_time:.3f} sec', sep='')\n",
    "        \n",
    "        epoch_loss /= dataset_sizes[phase]\n",
    "#         visualizer.add_epoch_loss(epoch_loss)\n",
    "        if phase == 'test' and epoch_loss < min_test_loss:\n",
    "            model.save_networks('best')\n",
    "            min_test_loss = epoch_loss\n",
    "            print(f'Updating best model at epoch {epoch}, average test loss: {epoch_loss:.4f}')\n",
    "    \n",
    "#     visualizer.plot_epoch_losses()\n",
    "    model.update_learning_rate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
